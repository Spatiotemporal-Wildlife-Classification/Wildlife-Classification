
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.15">
    
    
      
        <title>Data - Spatiotemporal Wildlife Classification Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#data-pipeline" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Spatiotemporal Wildlife Classification Docs" class="md-header__button md-logo" aria-label="Spatiotemporal Wildlife Classification Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Spatiotemporal Wildlife Classification Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Data
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Spatiotemporal Wildlife Classification Docs" class="md-nav__button md-logo" aria-label="Spatiotemporal Wildlife Classification Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Spatiotemporal Wildlife Classification Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Code Documentation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/" class="md-nav__link">
        Dataset
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../cascading_ensemble_classifier/" class="md-nav__link">
        Novel Cascading Ensemble Classifier
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../results/" class="md-nav__link">
        Results
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../thesis/" class="md-nav__link">
        Thesis report
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#data-pipeline" class="md-nav__link">
    Data Pipeline
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pipeline-details" class="md-nav__link">
    Pipeline Details
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline" class="md-nav__link">
    src.data.DataCleanPipeline
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline" class="md-nav__link">
    Pipeline
  </a>
  
    <nav class="md-nav" aria-label="Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.activate_flow" class="md-nav__link">
    activate_flow()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.aggregate_observations" class="md-nav__link">
    aggregate_observations()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.bad_data_separation" class="md-nav__link">
    bad_data_separation()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.batching" class="md-nav__link">
    batching()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.continuation" class="md-nav__link">
    continuation()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.coordinate_to_country_rate_limited" class="md-nav__link">
    coordinate_to_country_rate_limited()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.enforce_unique_ids" class="md-nav__link">
    enforce_unique_ids()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.format_bad_data" class="md-nav__link">
    format_bad_data()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.format_observation_dates" class="md-nav__link">
    format_observation_dates()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.generate_local_times" class="md-nav__link">
    generate_local_times()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.identify_bad_observations" class="md-nav__link">
    identify_bad_observations()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.percentage" class="md-nav__link">
    percentage()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.remove_na_working_columns" class="md-nav__link">
    remove_na_working_columns()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.remove_peripheral_columns" class="md-nav__link">
    remove_peripheral_columns()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.standardize_timezones" class="md-nav__link">
    standardize_timezones()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.write_bad_data" class="md-nav__link">
    write_bad_data()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#src.data.DataCleanPipeline.Pipeline.write_interim_data" class="md-nav__link">
    write_interim_data()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Data</h1>

<h2 id="data-pipeline">Data Pipeline</h2>
<p>The data pipeline serves to clean, structure, and process the raw observations sourced from 
 <a href="https://www.inaturalist.org/">iNaturalist</a>. </p>
<h2 id="pipeline-details">Pipeline Details</h2>


<div class="doc doc-object doc-module">


<a id="src.data.DataCleanPipeline"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="src.data.DataCleanPipeline.Pipeline" class="doc doc-heading">
        <code>Pipeline</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>Pipeline to clean raw data into interim data source.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>df_whole</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>Contains all aggregated observations</p></td>
        </tr>
        <tr>
          <td><code>df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>Dataframe containing the current batch of observations</p></td>
        </tr>
        <tr>
          <td><code>datasets</code></td>
          <td>
                <code>list</code>
          </td>
          <td><p>A list of individual observation csv files to be aggregated as raw data</p></td>
        </tr>
        <tr>
          <td><code>resource_path</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Path to raw data resources, from project root directory</p></td>
        </tr>
        <tr>
          <td><code>write_path</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Path to interim data resources, from project root directory</p></td>
        </tr>
        <tr>
          <td><code>interim_exists</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>A flag representing if an existing interim_data.csv file exists in the project.</p></td>
        </tr>
        <tr>
          <td><code>row_sum</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Contains the sum of aggregate observations. Value only initialized after dataset aggregation.</p></td>
        </tr>
        <tr>
          <td><code>start_time</code></td>
          <td>
                <code>DateTime</code>
          </td>
          <td><p>Records the start time of pipeline processing</p></td>
        </tr>
        <tr>
          <td><code>TEST</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>A flag indicating values should be initialized for testing purposes.</p></td>
        </tr>
        <tr>
          <td><code>test_df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>A direct dataframe insert for pipeline testing purposes</p></td>
        </tr>
        <tr>
          <td><code>interim_file</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Specification of the file to write data to after cleaning process. The naming convention is <code>&lt;taxon_parent_name&gt;_interim.csv</code></p></td>
        </tr>
        <tr>
          <td><code>bad_file</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>Specification of the file to write identified potentially bad observation images to.</p></td>
        </tr>
        <tr>
          <td><code>batch_size</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Size of individual batches that aggregate observations are broken down into.</p></td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Pipeline</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Pipeline to clean raw data into interim data source.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        df_whole (DataFrame): Contains all aggregated observations</span>
<span class="sd">        df (DataFrame): Dataframe containing the current batch of observations</span>
<span class="sd">        datasets (list): A list of individual observation csv files to be aggregated as raw data</span>
<span class="sd">        resource_path (str): Path to raw data resources, from project root directory</span>
<span class="sd">        write_path (str): Path to interim data resources, from project root directory</span>
<span class="sd">        interim_exists (bool): A flag representing if an existing interim_data.csv file exists in the project.</span>
<span class="sd">        row_sum (int): Contains the sum of aggregate observations. Value only initialized after dataset aggregation.</span>
<span class="sd">        start_time (DateTime): Records the start time of pipeline processing</span>
<span class="sd">        TEST (bool): A flag indicating values should be initialized for testing purposes.</span>
<span class="sd">        test_df (DataFrame): A direct dataframe insert for pipeline testing purposes</span>
<span class="sd">        interim_file (str): Specification of the file to write data to after cleaning process. The naming convention is `&lt;taxon_parent_name&gt;_interim.csv`</span>
<span class="sd">        bad_file (str): Specification of the file to write identified potentially bad observation images to.</span>
<span class="sd">        batch_size (int): Size of individual batches that aggregate observations are broken down into.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">interim_file</span> <span class="o">=</span> <span class="s2">&quot;felidae_interim.csv&quot;</span>
    <span class="n">bad_file</span> <span class="o">=</span> <span class="s1">&#39;bad_quality.csv&#39;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;observations_sample.csv&#39;</span><span class="p">],</span> <span class="n">test_df</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Initializes the observation pipeline.</span>

<span class="sd">        Note, it is recommended to process each data file one-by-one, but the pipeline has the capability to process several if required.</span>

<span class="sd">        Args:</span>
<span class="sd">            datasets (list): The list of datasets to process. The list should contain csv file names pointing to the dataset files.</span>
<span class="sd">            test_df (DataFrame): The capability to pass a pre-generated dataframe for pipeline testing purposes</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_df</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_path</span> <span class="o">=</span> <span class="n">root_dir</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/data/obs_and_meta/raw/&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">=</span> <span class="n">root_dir</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/data/obs_and_meta/interim/&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">activate_flow</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method details and executes the flow of the cleaning pipeline&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_observations</span><span class="p">()</span>  <span class="c1"># Aggregate all observation files</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">enforce_unique_ids</span><span class="p">()</span>  <span class="c1"># No duplicate observations</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">continuation</span><span class="p">()</span>  <span class="c1"># Continuation from interrupt/ start from scratch</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">remove_na_working_columns</span><span class="p">()</span>  <span class="c1"># Remove any NaN types from columns undergoing computation</span>

        <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">batching</span><span class="p">():</span>  <span class="c1"># Batching loop</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_separation</span><span class="p">()</span>  <span class="c1"># Detect bad quality observations from batch</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">format_observation_dates</span><span class="p">()</span>  <span class="c1"># Format sighting dates</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">generate_local_times</span><span class="p">()</span>  <span class="c1"># Generate local observation times</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">remove_peripheral_columns</span><span class="p">()</span>  <span class="c1"># Remove peripheral columns</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">write_interim_data</span><span class="p">()</span>  <span class="c1"># Write to interim data</span>

    <span class="k">def</span> <span class="nf">aggregate_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method aggregates all observations from separate files, placing them within a df for manipulation</span>

<span class="sd">        Method will check if dataframe is empty. This is to accommodate test cases which preloads the dataframe into</span>
<span class="sd">         the dataframe</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
                <span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_path</span> <span class="o">+</span> <span class="n">dataset</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">])</span>  <span class="c1"># Merge temp df into container df</span>

    <span class="k">def</span> <span class="nf">enforce_unique_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Removal of any duplicate observations utilizing their observation id</span>

<span class="sd">        In place duplicate removal such that changes are effected directly within df</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">],</span> <span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">continuation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_interim_df</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_bad_df</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method determines the status of the Data Cleaning Pipeline, enabling continuation without redundancies if</span>
<span class="sd">        the cleaning process is interrupted.</span>

<span class="sd">        This method enables testing through the test_interim_df dataframe that can be passed to it.</span>
<span class="sd">        However, within the pipeline this is automated, and no parameter is required.</span>
<span class="sd">        Method accesses the interim_data.csv file, and identifies already processes observations, removing them from the</span>
<span class="sd">        current cleaning proces.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_interim_df (DataFrame): This dataframe is None during Pipeline cleaning process, however it allows for the creation of an interim dataframe for testing purposes (Not running the entire pipeline.</span>
<span class="sd">            test_bad_df (DataFrame): This dataframe is None during the Pipeline process cleaning process, however is allows for the creation of a test_bad_df for testing purposes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">interim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="n">bad_quality_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="ow">and</span> <span class="n">test_interim_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Conditions for test cases</span>
            <span class="n">interim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">interim_df</span><span class="p">,</span> <span class="n">test_interim_df</span><span class="p">])</span>
            <span class="n">bad_quality_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bad_quality_df</span><span class="p">,</span> <span class="n">test_bad_df</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span><span class="p">:</span>  <span class="c1"># Non-test conditions when interim data file exists</span>
            <span class="n">interim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span><span class="p">:</span>  <span class="c1"># Non-test conditions when bad_quality data file exists</span>
            <span class="n">bad_quality_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">interim_df</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>  <span class="c1"># Removal of duplicate rows already written to interim data</span>
            <span class="n">interim_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">interim_df</span><span class="o">.</span><span class="n">index</span><span class="p">),</span> <span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">bad_quality_df</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>  <span class="c1"># Removal of duplicate rows already written to bad_quality data</span>
            <span class="n">bad_quality_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">bad_quality_df</span><span class="o">.</span><span class="n">index</span><span class="p">),</span> <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">remove_na_working_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; This method removes all rows with NaN values, specifically located within columns used for computation that require</span>
<span class="sd">        values.</span>

<span class="sd">         The &#39;working columns&#39; include date, time, time zone, and coordinates.</span>
<span class="sd">         If the removal creates an empty dataframe, the method exists execution, displaying an exit message.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">,</span> <span class="s1">&#39;latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;time_observed_at&#39;</span><span class="p">,</span> <span class="s1">&#39;time_zone&#39;</span><span class="p">],</span>
                             <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*********** No further correctly format to process ***********&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">batching</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; This method creates observation batches from the aggregate observations in order to iteratively process and clean</span>
<span class="sd">        data.</span>

<span class="sd">        This method processes each batch, iteratively writing to interim_data.csv.</span>
<span class="sd">        The DataFrame df_whole contains aggregate observations, while df contains the current batch.</span>
<span class="sd">        Each batch once generated is removed from df_whole until this dataframe is empty, concluding the batching process.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (bool): Method returns a boolean value. True if there are still observations to be batched and processes. False if df_whole is empty</span>
<span class="sd">            indicating the batching process has concluded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rows_remaining</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">percentage</span><span class="p">(</span><span class="n">rows_remaining</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">rows_remaining</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:]</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">percentage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows_remaining</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method generates and updates a status bar based on the progress of batching.</span>

<span class="sd">        Both percentage complete and running time metrics are displayed</span>
<span class="sd">        Method inspiration: Inspiration: https://www.geeksforgeeks.org/progress-bars-in-python/</span>

<span class="sd">        Args:</span>
<span class="sd">            rows_remaining (int): The number of rows remaining to be processed in the df_whole DataFrame.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">progress_bar_length</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="n">percentage_complete</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">-</span> <span class="n">rows_remaining</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span>
        <span class="n">filled</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">progress_bar_length</span> <span class="o">*</span> <span class="n">percentage_complete</span><span class="p">)</span>
        <span class="n">running_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>

        <span class="n">bar</span> <span class="o">=</span> <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="n">filled</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">progress_bar_length</span> <span class="o">-</span> <span class="n">filled</span><span class="p">)</span>
        <span class="n">percentage_display</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">percentage_complete</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">[</span><span class="si">%s</span><span class="s1">] </span><span class="si">%s%s</span><span class="s1"> ... running: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">bar</span><span class="p">,</span> <span class="n">percentage_display</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">,</span> <span class="n">running_time</span><span class="p">))</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">format_observation_dates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method ensures that raw data dates follow format yyyy-mm-dd. If the dates deviate they are removed from the dataframe.</span>

<span class="sd">        In place changes are effected within the classes dataframe df.</span>
<span class="sd">        Any date errors produced by incorrect date formats are transformed into NaT values, and the row removed from df</span>
<span class="sd">        Removal of the rows requires an index reset in order to facilitate testing operations on the cleaning pipeline.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">],</span>
                                                <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span>
                                                <span class="n">yearfirst</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">,</span>
                                                <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;observed_on != &quot;NaT&quot;&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">coordinate_to_country_rate_limited</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method takes data coordinates, and identifies the country of origin, creating a Country column within Interim data</span>

<span class="sd">        Note, this method is currently left out of the pipeline due to Nominitim rate limits.</span>

<span class="sd">        The Nomanitim geocoding API is utilized.</span>
<span class="sd">        Due to rate limiting of 1 request per second, a rate limiter has been introduced in order to respect the limits.</span>

<span class="sd">        This method modifies the current batch to include a country column with the country of observation specified for each observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set up the geolocation library</span>
        <span class="n">geolocator</span> <span class="o">=</span> <span class="n">Nominatim</span><span class="p">(</span><span class="n">user_agent</span><span class="o">=</span><span class="s2">&quot;Spatio_Tempt_Class&quot;</span><span class="p">)</span>
        <span class="n">geocode</span> <span class="o">=</span> <span class="n">RateLimiter</span><span class="p">(</span><span class="n">geolocator</span><span class="o">.</span><span class="n">reverse</span><span class="p">,</span> <span class="n">min_delay_seconds</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Combine lat and long into coordinates</span>
        <span class="n">latitudes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">latitude</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>  <span class="c1"># Generate a Series of latitude values as strings</span>
        <span class="n">longitudes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">longitude</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>  <span class="c1"># Generate a Series of longitude values as strings</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="n">latitudes</span> <span class="o">+</span> <span class="s1">&#39;, &#39;</span> <span class="o">+</span> <span class="n">longitudes</span>  <span class="c1"># Combined the latitudes and longitude values into a single coordinate Series</span>

        <span class="c1"># Retrieve countries from coordinates (rate limiting requests)</span>
        <span class="n">locations</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">geocode</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="n">exactly_one</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">locations</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">raw</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">][</span><span class="s1">&#39;country&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span>

    <span class="k">def</span> <span class="nf">generate_local_times</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method converts UTC time to correct local time utilizing the specified sighting timezone.</span>

<span class="sd">        The new column generated is labelled &quot;local_time_observed_at&quot; and can be found in interim data folder.</span>

<span class="sd">        The date conversion utilizes both date and time in the UTC format.</span>
<span class="sd">        This means, any day change (midnight -&gt; next day) are accounted for.</span>
<span class="sd">        The observed_on column is correct.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Standardize time zone formats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">standardize_timezones</span><span class="p">()</span>

        <span class="c1"># Generate local times by converting UTC to specified time zones</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;local_time_observed_at&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;time_observed_at&#39;</span><span class="p">],</span> <span class="n">utc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">astimezone</span><span class="p">(</span><span class="n">pytz</span><span class="o">.</span><span class="n">timezone</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;time_zone&#39;</span><span class="p">])),</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">standardize_timezones</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method generated timezones in a format accepted by the pytz library for use in the local time zone conversion</span>

<span class="sd">        This method utilizes the observation coordinates to return the time zone of the sighting.</span>
<span class="sd">        This timezone overwrites the &quot;time_zone&quot; column</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">finder</span> <span class="o">=</span> <span class="n">TimezoneFinder</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;time_zone&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">finder</span><span class="o">.</span><span class="n">timezone_at</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">],</span> <span class="n">lng</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">bad_data_separation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method performs the sub-process of bad data separation, formatting, and writing to the bad_data file&quot;&quot;&quot;</span>
        <span class="n">bad_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">identify_bad_observations</span><span class="p">()</span>
        <span class="n">bad_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_bad_data</span><span class="p">(</span><span class="n">bad_df</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_bad_data</span><span class="p">(</span><span class="n">bad_df</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">identify_bad_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method identifies probable bad quality images based on keyword extraction from the descriptions.</span>

<span class="sd">        The observations with identified keywords are excluded from the interim data, and instead written to the bad_data.csv file for manual filtering.</span>
<span class="sd">        Keywords list is created based on inspection of observation images and the descriptions of each observation.</span>

<span class="sd">        Keyword pattern identification is accomplished through the use of regex pattern matching</span>

<span class="sd">        Returns:</span>
<span class="sd">            (DataFrame): The method returns a DataFrame containing the identified potentially bad observations from within the current batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">description_indicators</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dead&#39;</span><span class="p">,</span> <span class="s1">&#39;road kill&#39;</span><span class="p">,</span> <span class="s1">&#39;road&#39;</span><span class="p">,</span> <span class="s1">&#39;scat&#39;</span><span class="p">,</span> <span class="s1">&#39;poo&#39;</span><span class="p">,</span> <span class="s1">&#39;killed&#39;</span><span class="p">,</span> <span class="s1">&#39;spoor&#39;</span><span class="p">,</span> <span class="s1">&#39;road-kill&#39;</span><span class="p">,</span> <span class="s1">&#39;remains&#39;</span><span class="p">,</span>
                                  <span class="s1">&#39;body&#39;</span><span class="p">,</span> <span class="s1">&#39;deceased&#39;</span><span class="p">,</span> <span class="s1">&#39;prey&#39;</span><span class="p">,</span> <span class="s1">&#39;fatality&#39;</span><span class="p">,</span> <span class="s1">&#39;tracks&#39;</span><span class="p">,</span> <span class="s1">&#39;trapped&#39;</span><span class="p">,</span> <span class="s1">&#39;bad&#39;</span><span class="p">,</span> <span class="s1">&#39;roadkilled&#39;</span><span class="p">,</span> <span class="s1">&#39;poop&#39;</span><span class="p">,</span>
                                  <span class="s1">&#39;crushed&#39;</span><span class="p">,</span> <span class="s1">&#39;kill&#39;</span><span class="p">,</span> <span class="s1">&#39;squashed&#39;</span><span class="p">,</span> <span class="s1">&#39;terrible&#39;</span><span class="p">,</span> <span class="s1">&#39;caught&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;blurry&#39;</span><span class="p">,</span> <span class="s1">&#39;destroyed&#39;</span><span class="p">,</span>
                                  <span class="s1">&#39;sidewalk&#39;</span><span class="p">,</span>
                                  <span class="s1">&#39;grounded&#39;</span><span class="p">]</span>
        <span class="n">regex_pattern</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key_word</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">key_word</span> <span class="ow">in</span> <span class="n">description_indicators</span><span class="p">])</span>
        <span class="nb">filter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">regex_pattern</span><span class="p">,</span> <span class="n">case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Filter descriptions to identify keywords</span>
        <span class="nb">filter</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Boolean filter</span>
        <span class="n">bad_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="nb">filter</span><span class="p">]</span>  <span class="c1"># Filter to produce bad_obs df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="nb">filter</span><span class="p">]</span>  <span class="c1"># Filter to remove bad_obs from df</span>
        <span class="n">bad_df</span><span class="p">[</span><span class="s1">&#39;image_quality&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;bad&#39;</span>  <span class="c1"># Label bad data image quality</span>
        <span class="k">return</span> <span class="n">bad_df</span>

    <span class="k">def</span> <span class="nf">remove_peripheral_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method removes all peripheral columns before writing dataframe to interim_data.csv&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">,</span> <span class="s1">&#39;local_time_observed_at&#39;</span><span class="p">,</span> <span class="s1">&#39;latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;longitude&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;positional_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;public_positional_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;image_url&#39;</span><span class="p">,</span> <span class="s1">&#39;license&#39;</span><span class="p">,</span> <span class="s1">&#39;geoprivacy&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;taxon_geoprivacy&#39;</span><span class="p">,</span> <span class="s1">&#39;scientific_name&#39;</span><span class="p">,</span> <span class="s1">&#39;common_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_id&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;taxon_kingdom_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_phylum_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_class_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_order_name&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;taxon_family_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_genus_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_species_name&#39;</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">format_bad_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bad_df</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method creates a sub-dataframe of only the image_url and the image quality (Index is observation ID)</span>

<span class="sd">        This subset creates the format that the bad quality images will be written to bad_quality.csv</span>

<span class="sd">        Args:</span>
<span class="sd">            bad_df (DataFrame): DataFrame containing all bad observations filtered from df</span>

<span class="sd">        Returns:</span>
<span class="sd">            (DataFrame): The method returns a DataFrame containing only the id, image_url, and image_quality columns (bad_data.csv format)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bad_df</span> <span class="o">=</span> <span class="n">bad_df</span><span class="p">[[</span><span class="s1">&#39;image_url&#39;</span><span class="p">,</span> <span class="s1">&#39;image_quality&#39;</span><span class="p">]]</span>
        <span class="k">return</span> <span class="n">bad_df</span>

    <span class="k">def</span> <span class="nf">write_bad_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bad_df</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Method performs similar operation to the write_interim_data() method, in this case specifically writing bad data</span>

<span class="sd">        This method should be refactored in conjunction with write_interim_data in order to minimize code repetition</span>

<span class="sd">        Args:</span>
<span class="sd">            bad_df (DataFrame): DataFrame containing the sub-dataframe of only id, image_url, and image_quality columns</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>  <span class="c1"># Identifies not in testing conditions</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span><span class="p">:</span>  <span class="c1"># If the file already exists, append the next batch   of bad data</span>
                <span class="n">bad_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Write bad_data file as no file exists</span>
                <span class="n">bad_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">write_interim_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Method writes current state of df into interim data folder in csv format&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">datasets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;observations_sample.csv&#39;</span><span class="p">],</span> <span class="n">test_df</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes the observation pipeline.</p>
<p>Note, it is recommended to process each data file one-by-one, but the pipeline has the capability to process several if required.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>datasets</code></td>
          <td>
                <code>list</code>
          </td>
          <td><p>The list of datasets to process. The list should contain csv file names pointing to the dataset files.</p></td>
          <td>
                <code>[&#39;observations_sample.csv&#39;]</code>
          </td>
        </tr>
        <tr>
          <td><code>test_df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>The capability to pass a pre-generated dataframe for pipeline testing purposes</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datasets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;observations_sample.csv&#39;</span><span class="p">],</span> <span class="n">test_df</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Initializes the observation pipeline.</span>

<span class="sd">    Note, it is recommended to process each data file one-by-one, but the pipeline has the capability to process several if required.</span>

<span class="sd">    Args:</span>
<span class="sd">        datasets (list): The list of datasets to process. The list should contain csv file names pointing to the dataset files.</span>
<span class="sd">        test_df (DataFrame): The capability to pass a pre-generated dataframe for pipeline testing purposes</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">test_df</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resource_path</span> <span class="o">=</span> <span class="n">root_dir</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/data/obs_and_meta/raw/&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">=</span> <span class="n">root_dir</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;/data/obs_and_meta/interim/&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.activate_flow" class="doc doc-heading">
<code class="highlight language-python"><span class="n">activate_flow</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method details and executes the flow of the cleaning pipeline</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">activate_flow</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method details and executes the flow of the cleaning pipeline&quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_observations</span><span class="p">()</span>  <span class="c1"># Aggregate all observation files</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">enforce_unique_ids</span><span class="p">()</span>  <span class="c1"># No duplicate observations</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">continuation</span><span class="p">()</span>  <span class="c1"># Continuation from interrupt/ start from scratch</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">remove_na_working_columns</span><span class="p">()</span>  <span class="c1"># Remove any NaN types from columns undergoing computation</span>

    <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">batching</span><span class="p">():</span>  <span class="c1"># Batching loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_separation</span><span class="p">()</span>  <span class="c1"># Detect bad quality observations from batch</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">format_observation_dates</span><span class="p">()</span>  <span class="c1"># Format sighting dates</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generate_local_times</span><span class="p">()</span>  <span class="c1"># Generate local observation times</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">remove_peripheral_columns</span><span class="p">()</span>  <span class="c1"># Remove peripheral columns</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_interim_data</span><span class="p">()</span>  <span class="c1"># Write to interim data</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.aggregate_observations" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_observations</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method aggregates all observations from separate files, placing them within a df for manipulation</p>
<p>Method will check if dataframe is empty. This is to accommodate test cases which preloads the dataframe into
 the dataframe</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">aggregate_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method aggregates all observations from separate files, placing them within a df for manipulation</span>

<span class="sd">    Method will check if dataframe is empty. This is to accommodate test cases which preloads the dataframe into</span>
<span class="sd">     the dataframe</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_path</span> <span class="o">+</span> <span class="n">dataset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">])</span>  <span class="c1"># Merge temp df into container df</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.bad_data_separation" class="doc doc-heading">
<code class="highlight language-python"><span class="n">bad_data_separation</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method performs the sub-process of bad data separation, formatting, and writing to the bad_data file</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">bad_data_separation</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method performs the sub-process of bad data separation, formatting, and writing to the bad_data file&quot;&quot;&quot;</span>
    <span class="n">bad_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">identify_bad_observations</span><span class="p">()</span>
    <span class="n">bad_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">format_bad_data</span><span class="p">(</span><span class="n">bad_df</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_bad_data</span><span class="p">(</span><span class="n">bad_df</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.batching" class="doc doc-heading">
<code class="highlight language-python"><span class="n">batching</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>This method creates observation batches from the aggregate observations in order to iteratively process and clean
data.</p>
<p>This method processes each batch, iteratively writing to interim_data.csv.
The DataFrame df_whole contains aggregate observations, while df contains the current batch.
Each batch once generated is removed from df_whole until this dataframe is empty, concluding the batching process.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>bool</code>
          </td>
          <td><p>Method returns a boolean value. True if there are still observations to be batched and processes. False if df_whole is empty</p></td>
        </tr>
        <tr>
          <td>
                <code>bool</code>
          </td>
          <td><p>indicating the batching process has concluded.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">batching</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; This method creates observation batches from the aggregate observations in order to iteratively process and clean</span>
<span class="sd">    data.</span>

<span class="sd">    This method processes each batch, iteratively writing to interim_data.csv.</span>
<span class="sd">    The DataFrame df_whole contains aggregate observations, while df contains the current batch.</span>
<span class="sd">    Each batch once generated is removed from df_whole until this dataframe is empty, concluding the batching process.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (bool): Method returns a boolean value. True if there are still observations to be batched and processes. False if df_whole is empty</span>
<span class="sd">        indicating the batching process has concluded.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rows_remaining</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">percentage</span><span class="p">(</span><span class="n">rows_remaining</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">rows_remaining</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:]</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.continuation" class="doc doc-heading">
<code class="highlight language-python"><span class="n">continuation</span><span class="p">(</span><span class="n">test_interim_df</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_bad_df</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method determines the status of the Data Cleaning Pipeline, enabling continuation without redundancies if
the cleaning process is interrupted.</p>
<p>This method enables testing through the test_interim_df dataframe that can be passed to it.
However, within the pipeline this is automated, and no parameter is required.
Method accesses the interim_data.csv file, and identifies already processes observations, removing them from the
current cleaning proces.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>test_interim_df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>This dataframe is None during Pipeline cleaning process, however it allows for the creation of an interim dataframe for testing purposes (Not running the entire pipeline.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>test_bad_df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>This dataframe is None during the Pipeline process cleaning process, however is allows for the creation of a test_bad_df for testing purposes.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">continuation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_interim_df</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_bad_df</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method determines the status of the Data Cleaning Pipeline, enabling continuation without redundancies if</span>
<span class="sd">    the cleaning process is interrupted.</span>

<span class="sd">    This method enables testing through the test_interim_df dataframe that can be passed to it.</span>
<span class="sd">    However, within the pipeline this is automated, and no parameter is required.</span>
<span class="sd">    Method accesses the interim_data.csv file, and identifies already processes observations, removing them from the</span>
<span class="sd">    current cleaning proces.</span>

<span class="sd">    Args:</span>
<span class="sd">        test_interim_df (DataFrame): This dataframe is None during Pipeline cleaning process, however it allows for the creation of an interim dataframe for testing purposes (Not running the entire pipeline.</span>
<span class="sd">        test_bad_df (DataFrame): This dataframe is None during the Pipeline process cleaning process, however is allows for the creation of a test_bad_df for testing purposes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">interim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">bad_quality_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="ow">and</span> <span class="n">test_interim_df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Conditions for test cases</span>
        <span class="n">interim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">interim_df</span><span class="p">,</span> <span class="n">test_interim_df</span><span class="p">])</span>
        <span class="n">bad_quality_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bad_quality_df</span><span class="p">,</span> <span class="n">test_bad_df</span><span class="p">])</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span><span class="p">:</span>  <span class="c1"># Non-test conditions when interim data file exists</span>
        <span class="n">interim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span><span class="p">:</span>  <span class="c1"># Non-test conditions when bad_quality data file exists</span>
        <span class="n">bad_quality_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">interim_df</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>  <span class="c1"># Removal of duplicate rows already written to interim data</span>
        <span class="n">interim_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">interim_df</span><span class="o">.</span><span class="n">index</span><span class="p">),</span> <span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">bad_quality_df</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>  <span class="c1"># Removal of duplicate rows already written to bad_quality data</span>
        <span class="n">bad_quality_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">bad_quality_df</span><span class="o">.</span><span class="n">index</span><span class="p">),</span> <span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.coordinate_to_country_rate_limited" class="doc doc-heading">
<code class="highlight language-python"><span class="n">coordinate_to_country_rate_limited</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method takes data coordinates, and identifies the country of origin, creating a Country column within Interim data</p>
<p>Note, this method is currently left out of the pipeline due to Nominitim rate limits.</p>
<p>The Nomanitim geocoding API is utilized.
Due to rate limiting of 1 request per second, a rate limiter has been introduced in order to respect the limits.</p>
<p>This method modifies the current batch to include a country column with the country of observation specified for each observation.</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">coordinate_to_country_rate_limited</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method takes data coordinates, and identifies the country of origin, creating a Country column within Interim data</span>

<span class="sd">    Note, this method is currently left out of the pipeline due to Nominitim rate limits.</span>

<span class="sd">    The Nomanitim geocoding API is utilized.</span>
<span class="sd">    Due to rate limiting of 1 request per second, a rate limiter has been introduced in order to respect the limits.</span>

<span class="sd">    This method modifies the current batch to include a country column with the country of observation specified for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Set up the geolocation library</span>
    <span class="n">geolocator</span> <span class="o">=</span> <span class="n">Nominatim</span><span class="p">(</span><span class="n">user_agent</span><span class="o">=</span><span class="s2">&quot;Spatio_Tempt_Class&quot;</span><span class="p">)</span>
    <span class="n">geocode</span> <span class="o">=</span> <span class="n">RateLimiter</span><span class="p">(</span><span class="n">geolocator</span><span class="o">.</span><span class="n">reverse</span><span class="p">,</span> <span class="n">min_delay_seconds</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Combine lat and long into coordinates</span>
    <span class="n">latitudes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">latitude</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>  <span class="c1"># Generate a Series of latitude values as strings</span>
    <span class="n">longitudes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">longitude</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>  <span class="c1"># Generate a Series of longitude values as strings</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="n">latitudes</span> <span class="o">+</span> <span class="s1">&#39;, &#39;</span> <span class="o">+</span> <span class="n">longitudes</span>  <span class="c1"># Combined the latitudes and longitude values into a single coordinate Series</span>

    <span class="c1"># Retrieve countries from coordinates (rate limiting requests)</span>
    <span class="n">locations</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">geocode</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;en&#39;</span><span class="p">,</span> <span class="n">exactly_one</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">locations</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">raw</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">][</span><span class="s1">&#39;country&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.enforce_unique_ids" class="doc doc-heading">
<code class="highlight language-python"><span class="n">enforce_unique_ids</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Removal of any duplicate observations utilizing their observation id</p>
<p>In place duplicate removal such that changes are effected directly within df</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">enforce_unique_ids</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Removal of any duplicate observations utilizing their observation id</span>

<span class="sd">    In place duplicate removal such that changes are effected directly within df</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">],</span> <span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.format_bad_data" class="doc doc-heading">
<code class="highlight language-python"><span class="n">format_bad_data</span><span class="p">(</span><span class="n">bad_df</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method creates a sub-dataframe of only the image_url and the image quality (Index is observation ID)</p>
<p>This subset creates the format that the bad quality images will be written to bad_quality.csv</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>bad_df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>DataFrame containing all bad observations filtered from df</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>The method returns a DataFrame containing only the id, image_url, and image_quality columns (bad_data.csv format)</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">format_bad_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bad_df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method creates a sub-dataframe of only the image_url and the image quality (Index is observation ID)</span>

<span class="sd">    This subset creates the format that the bad quality images will be written to bad_quality.csv</span>

<span class="sd">    Args:</span>
<span class="sd">        bad_df (DataFrame): DataFrame containing all bad observations filtered from df</span>

<span class="sd">    Returns:</span>
<span class="sd">        (DataFrame): The method returns a DataFrame containing only the id, image_url, and image_quality columns (bad_data.csv format)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bad_df</span> <span class="o">=</span> <span class="n">bad_df</span><span class="p">[[</span><span class="s1">&#39;image_url&#39;</span><span class="p">,</span> <span class="s1">&#39;image_quality&#39;</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">bad_df</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.format_observation_dates" class="doc doc-heading">
<code class="highlight language-python"><span class="n">format_observation_dates</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method ensures that raw data dates follow format yyyy-mm-dd. If the dates deviate they are removed from the dataframe.</p>
<p>In place changes are effected within the classes dataframe df.
Any date errors produced by incorrect date formats are transformed into NaT values, and the row removed from df
Removal of the rows requires an index reset in order to facilitate testing operations on the cleaning pipeline.</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">format_observation_dates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method ensures that raw data dates follow format yyyy-mm-dd. If the dates deviate they are removed from the dataframe.</span>

<span class="sd">    In place changes are effected within the classes dataframe df.</span>
<span class="sd">    Any date errors produced by incorrect date formats are transformed into NaT values, and the row removed from df</span>
<span class="sd">    Removal of the rows requires an index reset in order to facilitate testing operations on the cleaning pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">],</span>
                                            <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span>
                                            <span class="n">yearfirst</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                            <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">,</span>
                                            <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;observed_on != &quot;NaT&quot;&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.generate_local_times" class="doc doc-heading">
<code class="highlight language-python"><span class="n">generate_local_times</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method converts UTC time to correct local time utilizing the specified sighting timezone.</p>
<p>The new column generated is labelled "local_time_observed_at" and can be found in interim data folder.</p>
<p>The date conversion utilizes both date and time in the UTC format.
This means, any day change (midnight -&gt; next day) are accounted for.
The observed_on column is correct.</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate_local_times</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method converts UTC time to correct local time utilizing the specified sighting timezone.</span>

<span class="sd">    The new column generated is labelled &quot;local_time_observed_at&quot; and can be found in interim data folder.</span>

<span class="sd">    The date conversion utilizes both date and time in the UTC format.</span>
<span class="sd">    This means, any day change (midnight -&gt; next day) are accounted for.</span>
<span class="sd">    The observed_on column is correct.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Standardize time zone formats</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">standardize_timezones</span><span class="p">()</span>

    <span class="c1"># Generate local times by converting UTC to specified time zones</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;local_time_observed_at&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;time_observed_at&#39;</span><span class="p">],</span> <span class="n">utc</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">astimezone</span><span class="p">(</span><span class="n">pytz</span><span class="o">.</span><span class="n">timezone</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;time_zone&#39;</span><span class="p">])),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.identify_bad_observations" class="doc doc-heading">
<code class="highlight language-python"><span class="n">identify_bad_observations</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method identifies probable bad quality images based on keyword extraction from the descriptions.</p>
<p>The observations with identified keywords are excluded from the interim data, and instead written to the bad_data.csv file for manual filtering.
Keywords list is created based on inspection of observation images and the descriptions of each observation.</p>
<p>Keyword pattern identification is accomplished through the use of regex pattern matching</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>The method returns a DataFrame containing the identified potentially bad observations from within the current batch.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">identify_bad_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method identifies probable bad quality images based on keyword extraction from the descriptions.</span>

<span class="sd">    The observations with identified keywords are excluded from the interim data, and instead written to the bad_data.csv file for manual filtering.</span>
<span class="sd">    Keywords list is created based on inspection of observation images and the descriptions of each observation.</span>

<span class="sd">    Keyword pattern identification is accomplished through the use of regex pattern matching</span>

<span class="sd">    Returns:</span>
<span class="sd">        (DataFrame): The method returns a DataFrame containing the identified potentially bad observations from within the current batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">description_indicators</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;dead&#39;</span><span class="p">,</span> <span class="s1">&#39;road kill&#39;</span><span class="p">,</span> <span class="s1">&#39;road&#39;</span><span class="p">,</span> <span class="s1">&#39;scat&#39;</span><span class="p">,</span> <span class="s1">&#39;poo&#39;</span><span class="p">,</span> <span class="s1">&#39;killed&#39;</span><span class="p">,</span> <span class="s1">&#39;spoor&#39;</span><span class="p">,</span> <span class="s1">&#39;road-kill&#39;</span><span class="p">,</span> <span class="s1">&#39;remains&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;body&#39;</span><span class="p">,</span> <span class="s1">&#39;deceased&#39;</span><span class="p">,</span> <span class="s1">&#39;prey&#39;</span><span class="p">,</span> <span class="s1">&#39;fatality&#39;</span><span class="p">,</span> <span class="s1">&#39;tracks&#39;</span><span class="p">,</span> <span class="s1">&#39;trapped&#39;</span><span class="p">,</span> <span class="s1">&#39;bad&#39;</span><span class="p">,</span> <span class="s1">&#39;roadkilled&#39;</span><span class="p">,</span> <span class="s1">&#39;poop&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;crushed&#39;</span><span class="p">,</span> <span class="s1">&#39;kill&#39;</span><span class="p">,</span> <span class="s1">&#39;squashed&#39;</span><span class="p">,</span> <span class="s1">&#39;terrible&#39;</span><span class="p">,</span> <span class="s1">&#39;caught&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;blurry&#39;</span><span class="p">,</span> <span class="s1">&#39;destroyed&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;sidewalk&#39;</span><span class="p">,</span>
                              <span class="s1">&#39;grounded&#39;</span><span class="p">]</span>
    <span class="n">regex_pattern</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">key_word</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">key_word</span> <span class="ow">in</span> <span class="n">description_indicators</span><span class="p">])</span>
    <span class="nb">filter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">regex_pattern</span><span class="p">,</span> <span class="n">case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Filter descriptions to identify keywords</span>
    <span class="nb">filter</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Boolean filter</span>
    <span class="n">bad_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="nb">filter</span><span class="p">]</span>  <span class="c1"># Filter to produce bad_obs df</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="nb">filter</span><span class="p">]</span>  <span class="c1"># Filter to remove bad_obs from df</span>
    <span class="n">bad_df</span><span class="p">[</span><span class="s1">&#39;image_quality&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;bad&#39;</span>  <span class="c1"># Label bad data image quality</span>
    <span class="k">return</span> <span class="n">bad_df</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.percentage" class="doc doc-heading">
<code class="highlight language-python"><span class="n">percentage</span><span class="p">(</span><span class="n">rows_remaining</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method generates and updates a status bar based on the progress of batching.</p>
<p>Both percentage complete and running time metrics are displayed
Method inspiration: Inspiration: https://www.geeksforgeeks.org/progress-bars-in-python/</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>rows_remaining</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>The number of rows remaining to be processed in the df_whole DataFrame.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">percentage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows_remaining</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method generates and updates a status bar based on the progress of batching.</span>

<span class="sd">    Both percentage complete and running time metrics are displayed</span>
<span class="sd">    Method inspiration: Inspiration: https://www.geeksforgeeks.org/progress-bars-in-python/</span>

<span class="sd">    Args:</span>
<span class="sd">        rows_remaining (int): The number of rows remaining to be processed in the df_whole DataFrame.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">progress_bar_length</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">percentage_complete</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span> <span class="o">-</span> <span class="n">rows_remaining</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_sum</span>
    <span class="n">filled</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">progress_bar_length</span> <span class="o">*</span> <span class="n">percentage_complete</span><span class="p">)</span>
    <span class="n">running_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>

    <span class="n">bar</span> <span class="o">=</span> <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="n">filled</span> <span class="o">+</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">progress_bar_length</span> <span class="o">-</span> <span class="n">filled</span><span class="p">)</span>
    <span class="n">percentage_display</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">percentage_complete</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">[</span><span class="si">%s</span><span class="s1">] </span><span class="si">%s%s</span><span class="s1"> ... running: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">bar</span><span class="p">,</span> <span class="n">percentage_display</span><span class="p">,</span> <span class="s1">&#39;%&#39;</span><span class="p">,</span> <span class="n">running_time</span><span class="p">))</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.remove_na_working_columns" class="doc doc-heading">
<code class="highlight language-python"><span class="n">remove_na_working_columns</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>This method removes all rows with NaN values, specifically located within columns used for computation that require
values.</p>
<p>The 'working columns' include date, time, time zone, and coordinates.
 If the removal creates an empty dataframe, the method exists execution, displaying an exit message.</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">remove_na_working_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; This method removes all rows with NaN values, specifically located within columns used for computation that require</span>
<span class="sd">    values.</span>

<span class="sd">     The &#39;working columns&#39; include date, time, time zone, and coordinates.</span>
<span class="sd">     If the removal creates an empty dataframe, the method exists execution, displaying an exit message.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">,</span> <span class="s1">&#39;latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;longitude&#39;</span><span class="p">,</span> <span class="s1">&#39;time_observed_at&#39;</span><span class="p">,</span> <span class="s1">&#39;time_zone&#39;</span><span class="p">],</span>
                         <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_whole</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*********** No further correctly format to process ***********&quot;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.remove_peripheral_columns" class="doc doc-heading">
<code class="highlight language-python"><span class="n">remove_peripheral_columns</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method removes all peripheral columns before writing dataframe to interim_data.csv</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">remove_peripheral_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method removes all peripheral columns before writing dataframe to interim_data.csv&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;observed_on&#39;</span><span class="p">,</span> <span class="s1">&#39;local_time_observed_at&#39;</span><span class="p">,</span> <span class="s1">&#39;latitude&#39;</span><span class="p">,</span> <span class="s1">&#39;longitude&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;positional_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;public_positional_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;image_url&#39;</span><span class="p">,</span> <span class="s1">&#39;license&#39;</span><span class="p">,</span> <span class="s1">&#39;geoprivacy&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;taxon_geoprivacy&#39;</span><span class="p">,</span> <span class="s1">&#39;scientific_name&#39;</span><span class="p">,</span> <span class="s1">&#39;common_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_id&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;taxon_kingdom_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_phylum_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_class_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_order_name&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;taxon_family_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_genus_name&#39;</span><span class="p">,</span> <span class="s1">&#39;taxon_species_name&#39;</span><span class="p">]]</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.standardize_timezones" class="doc doc-heading">
<code class="highlight language-python"><span class="n">standardize_timezones</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method generated timezones in a format accepted by the pytz library for use in the local time zone conversion</p>
<p>This method utilizes the observation coordinates to return the time zone of the sighting.
This timezone overwrites the "time_zone" column</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">standardize_timezones</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method generated timezones in a format accepted by the pytz library for use in the local time zone conversion</span>

<span class="sd">    This method utilizes the observation coordinates to return the time zone of the sighting.</span>
<span class="sd">    This timezone overwrites the &quot;time_zone&quot; column</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">finder</span> <span class="o">=</span> <span class="n">TimezoneFinder</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;time_zone&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">finder</span><span class="o">.</span><span class="n">timezone_at</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;latitude&#39;</span><span class="p">],</span> <span class="n">lng</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;longitude&#39;</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.write_bad_data" class="doc doc-heading">
<code class="highlight language-python"><span class="n">write_bad_data</span><span class="p">(</span><span class="n">bad_df</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method performs similar operation to the write_interim_data() method, in this case specifically writing bad data</p>
<p>This method should be refactored in conjunction with write_interim_data in order to minimize code repetition</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>bad_df</code></td>
          <td>
                <code>DataFrame</code>
          </td>
          <td><p>DataFrame containing the sub-dataframe of only id, image_url, and image_quality columns</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">write_bad_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bad_df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Method performs similar operation to the write_interim_data() method, in this case specifically writing bad data</span>

<span class="sd">    This method should be refactored in conjunction with write_interim_data in order to minimize code repetition</span>

<span class="sd">    Args:</span>
<span class="sd">        bad_df (DataFrame): DataFrame containing the sub-dataframe of only id, image_url, and image_quality columns</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>  <span class="c1"># Identifies not in testing conditions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_data_exists</span><span class="p">:</span>  <span class="c1"># If the file already exists, append the next batch   of bad data</span>
            <span class="n">bad_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Write bad_data file as no file exists</span>
            <span class="n">bad_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="src.data.DataCleanPipeline.Pipeline.write_interim_data" class="doc doc-heading">
<code class="highlight language-python"><span class="n">write_interim_data</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Method writes current state of df into interim data folder in csv format</p>

      <details class="quote">
        <summary>Source code in <code>src/data/DataCleanPipeline.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">write_interim_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Method writes current state of df into interim data folder in csv format&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_exists</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_path</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">interim_file</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.b4d07000.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>