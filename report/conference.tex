\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[table]{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{A Novel use of Spatio-temporal Metadata to Bolster Wildlife Classification\\
\thanks{This thesis was prepared in partial fulfilment of the requirements for the Degree of Bachelor of Science in Data Science and Artificial Intelligence, Maastricht University. Supervisor(s): Christof Sieler, Mirela Popa}
}

\author{\IEEEauthorblockN{Travis Dawson}
\IEEEauthorblockA{\textit{Department of Advanced Computing Sciences} \\
\textit{Faculty of Science and Engineering}\\
\textit{Maastricht University}\\
Maastricht, The Netherlands}
}

\maketitle

\begin{abstract}
    Still to-do
\end{abstract}

\begin{IEEEkeywords}
Wildlife Classification, Convolutional Neural Network (CNN), Meta-data, Spatio-temporal, automated species identification, taxonomy, images, 
\end{IEEEkeywords}

\section{Introduction}
    Machine Learning (ML) in the form of automated species classification (classification) serves as a multi-faceted link to the animal kingdom, fulfilling a diverse role, including population estimates \cite{Miao_Gaynor_Wang_Liu_Muellerklein_Norouzzadeh_McInturff_Bowie_Nathan_Yu_2019},\cite{Schneider_Greenberg_Taylor_Kremer_2020}, animal behaviour \cite{Chen_Little_Mihaylova_Delahay_Cox_2019}, conservation \cite{Wäldchen_Mäder_2018}, \cite{Simões_Bouveyron_Precioso_2023}, and ecological research \cite{Nazir_Kaleem_2021} . Automated classification, removes the bottle-neck of manual image labelling, saving researchers time and funding \cite{Chen_Little_Mihaylova_Delahay_Cox_2019}, \cite{Miao_Gaynor_Wang_Liu_Muellerklein_Norouzzadeh_McInturff_Bowie_Nathan_Yu_2019}.
    Advances in classification, allow researchers to ask the questions, "what are they doing?", "where are they?", "who are they with?", amongst others \cite{Gomez_Villa_Salazar_Vargas_2017}. These questions can be tailored to the taxonomic level, or to an individual level, whereby each individual contains its own unique identifying pattern/ visual representation used to identify it \cite{Clapham_Miller_Nguyen_Van_Horn_2022}. 
    \\

    Classification utilizes images in order to learn the unique visual traits of animals, in order to accurately classify them. Images are sourced primarily from Camera-traps, and Citizen-Science platforms. Camera-traps are fixed-location strategically placed camera's that capture a burst of images, when a motion sensor is tripped, indicating an animal's presence \cite{Schneider_Greenberg_Taylor_Kremer_2020}. Prominent camera-trap networks include the Snapshot-safari project \cite{snapshot_safari}. Citizen Science platforms, such as iNaturalist \cite{iNaturalist} and Zooniverse \cite{zooniverse.org}, allow for individuals to upload captured images, and through group consensus decide on the species present in the image. 
    The quality and quantity of images within these sources, present a challenge to classification methods, due to the harsh-conditions in which they are captured, the varied quality of captured images, and the unbalanced quantity of species captured (a long-tailed distribution) \cite{Van_Horn_Mac_Aodha_Song_Cui_Sun_Shepard_Adam_Perona_Belongie_2018b}. 
    \\

    Datasets such as ImageNet \cite{ImageNet}, and the iNaturalist challenges \cite{Van_Horn_Mac_Aodha_Song_Cui_Sun_Shepard_Adam_Perona_Belongie_2018b} provide a historical comparison of state-of-the-art image classifiers. Two Convolutional Neural Network (CNN) models, AlexNet \cite{Krizhevsky_Sutskever_Hinton_2017a} and VGG-16 \cite{Simonyan2014-ww} provided the initial success of image classification between 2013-2014 beating human recall levels \cite{Wäldchen_Mäder_2018}, achieving a $39.7\%$ top-1\% error rate and a $24.7\%$ error rate on the ImageNet dataset. Modern comparisons and their variants include, ResNet \cite{He_Zhang_Ren_Sun_2016} and EfficientNet \cite{Tan2019} CNN's of which the latter, achieved a $88.4\%$ top-1\% accuracy on ImageNet. Deviations from the CNN models to Vision Transfer models, such as ViT-G/14 \cite{Zhai_Kolesnikov_Houlsby_Beyer_2022} achieved as high as $90.45\%$ top-1\% accuracy.
    \\ 

    However, the metrics of success highlight, a prominent issue. Not all classes are capable of being correctly classified, especially when there is a lack of sufficient training images of sufficient quality. However with the rise of technology, meta-data is ever-present in the images captured, leading to research into its use as a means of bolstering existing image classification. 
    Terry et al. \cite{Terry_Roy_August_2019}, determined a $9.1\%$ top-1\% accuracy improvement, in the classification of Ladybird records when meta-data methods were included in image classification. Similarly, Tang et al. \cite{tang_paluri_fei-fei_fergus_bourdev_2015} discovered an almost 7\% gain in mean average precision. The use of meta-data is considered to be a critical factor in animal classification going forward \cite{Wäldchen_Mäder_2018}. 
    \\

    This paper, proposes a novel methodology in order to bolster the accuracy and taxonomic depth of prediction of existing wildlife classification methods, through the use of meta-data modelling. 
    The use of image meta-data to extended extensively to include the sighting's immediate environmental conditions (temperature, rainfall, wind, etc), the geographic conditions, and temporal aspect of the sighting (season, time of day, dark/light, etc). In order to build a comprehensive meta-model capable of capturing the relationship between the environmental and geographic conditions of a sighting and the wildlife present.
    Additionally branching from the concept of a hierarchical taxonomic classifier introduced by Gomez-Donoso et al. \cite{gomez-donoso_escalona_pérez-esteve_cazorla_2021}, this paper introduces a novel ensemble method of classification and meta-data cohesion, whereby classification occurs at each taxonomic level, allowing differing levels of classification abstraction. 
    We examine if the proposed novel approach is capable of the following: 
    \\
    
    \begin{enumerate}
        \item Improving the overall and long-tail accuracy of wildlife classification against known baseline methods. 
        \item Extend the taxonomic depth of classification prediction to the Sub-species taxonomic level.
    \end{enumerate}


    
\section{Methods and Materials}
    \subsection{Data}
        \subsubsection{Observations}
        Observations were sourced from the Citizen Science platform iNaturalist \cite{iNaturalist}. Specifically targeting a subset of the Animalia kingdom, \textit{Elephantidae} and \textit{Felidae} taxonomic orders. These chosen subsets, were selected due to the diverse and global nature of their observations, the elusive and remote destinations the individual's inhabit, as well as the resulting characteristic long-tailed distribution they possess, such that they serve as generic representatives of common issues within wildlife classification. Each observation contains an image, labels, taxonomic information, geographic coordinate, date, and time of the observation.

        Table \ref{table: taxonomic_breakdown} in the Appendix, provides a comprehensive breakdown of taxonomic counts of the generated dataset. Evident is the unbalanced classes characteristic of wildlife datasets \cite{Van_Horn_Mac_Aodha_Song_Cui_Sun_Shepard_Adam_Perona_Belongie_2018b}, which is further exacerbated at lower levels of the taxonomic hierarchy.

        \subsubsection{Environmental Data}
        Each wildlife observation's meta-data is limited to include the latitude \& longitude, date, and time of observation. In order to supplement the meta-data with the immediate environmental, geographic, and temporal conditions, the Open-Meteo \cite{openmeteo} open-source weather API us utilized. Open-Meteo sources information directly from Copernicus satellite data \cite{era5}. The weather API allows for the collection of daily aggregate information, and hourly data, with a resolution of $11.0$ kilometers, providing a snapshot of the environmental conditions of the observation. The collected meta-data enables the extraction of further environmental features included within the spatiotemporal snapshot. Table \ref{table: open_meteo_summary} in the Appendix provides a comprehensive list of spatiotemporal features per observation.

    
    \subsection{Methods}
    Questions for the Language center:
    I have two long tables that I would like to include in the appendix, but would like to show a short description of those tables in the Data section as above. Any advise as to the correct format for achieving this would be greatly appreciated. Many thanks!

\section{Implementation}

\section{Experimentation}

\section{Results}

\section{Discussion}

\section{Conclusion}


\bibliographystyle{plain}
\bibliography{report/bibliography}

\section{Appendix}

    \begin{table}[htbp]
        \caption{Dataset Taxonomic Breakdown}
        \begin{center}
        \begin{tabular}{|c|c|c|}
        \hline
        Taxonomic Name & Dataset Count & Taxonomic Level \\
        \hline
        Felidae & 44710 & Order \\
        Elephantidae & 11291 & Order \\
        \hline
        Lynx & 20139 & Genus \\
        Panthera & 12411 & Genus \\
        Puma & 5239 & Genus \\
        Leopardus & 2220 & Genus \\
        Acinonyx & 1872 & Genus \\
        Felis & 991 & Genus \\
        Caracal & 595 & Genus \\
        Herpailurus & 448 & Genus \\
        Leptailurus & 442 & Genus \\
        Prionailurus & 291 & Genus \\
        Neofelis & 24 & Genus \\
        Otocolobus & 20 & Genus \\
        Pardofelis & 11 & Genus \\
        Catopuma & 7 & Genus \\
        Loxodonta & 9407 & Genus \\
        Elephas & 1885 & Genus \\
        \hline
        \end{tabular}
        \label{table: taxonomic_breakdown}
        \end{center}
    \end{table}

    \begin{table}[htbp]
        \caption{Meta-data Features}
        \begin{center}
        \begin{tabular}{|c|c|c|}
        \hline
        Feature & Description & Unit/ Format \\
        \hline
        Coordinates & World Geodetic System (WGS84) & (latitude, longitude) \\
        Elevation & Meters above sea level & Meters \\
        Ground temperature & Air temperature 2 meters above ground & Celsius \\
        Relative humidity & Humidity 2 meters above ground & \% \\
        Hourly precipitation & Hourly precipitation sum & Milimeters \\
        Hourly snowfall & Hourly snowfall sum & Centimeters \\
        Cloudcover & Cloudcover within the immediate area & \% of area covered \\
        \hline
        \end{tabular}
        \label{table: open_meteo_summary}
        \end{center}
    \end{table}
\end{document}
